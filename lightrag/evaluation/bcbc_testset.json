{
  "test_cases": [
    {
      "question": "How can the model be improved to correctly identify and interpret logical connectives in building code?",
      "ground_truth": "To improve the model's ability to correctly identify and interpret logical connectives in building code, a three-step improvement process is proposed: 1. Breaking down Logic Extraction: First, breaking down the task of logic extraction into smaller, more manageable components would break the logic into parts (to be concatenated at a later stage) and shorten the length of prompts. This could allow the model to focus on less complicated logic structures, improving accuracy. 2. Fine-Tuning the Model: Second, fine-tuning the GPT model on a dataset of building code-specific logic would further enhance the accuracy of extractions, as it would learn the particular nuances of the BCBC\u2019s logical structure. 3. Tuning the Temperature Parameter: Third, tuning the temperature parameter to control the randomness and creativity of the generated responses can also help in improving the model's ability to generate coherent and accurate results.",
      "project": "bcbc_evaluation",
      "context": "ances where\nthe model failed to correctly identify the logical connectives (OR, AND, NOT) between codes. This was most\napparent with codes requiring a list of lower level codes (clauses, subclauses) to be satisfied. The logical connectives\nconnecting these lower level codes were occasionally misinterpreted; AND instead of OR, and vise versa.\nSolution: A three-step improvement process is proposed:\n1. Breaking Down Logic Extraction:First, breaking down the task of logic extraction into smaller, more\nmanageable components would break the logic into parts (to be concatenated at a later stage) and shorten\nthe length of prompts. This could allow the model to focus on less complicated logic structures, improving\naccuracy.\n2. Fine-Tuning the Model:Second, fine-tuning the GPT model on a dataset of building code-specific logic\nwould further enhance the accuracy of extractions, as it would learn the particular nuances of the BCBC\u2019s\nlogical structure.\n3. Tuning the Temperature Parameter:The third "
    },
    {
      "question": "What is the minimum number of streets a building can face to be classified as 'Sprinklered'?",
      "ground_truth": "A building can face at most 2 streets to be classified as 'Sprinklered'.",
      "project": "bcbc_evaluation",
      "context": "pe (combustible or non-combustible)\n5. Sprinklered (yes or no)\n6. Street Exposure (number of streets a building faces)\nBy using these six criteria, it is possible to narrow down the occupancy classification, which serves as a powerful filter\nto reduce the dataset significantly before engaging with the logic-extraction layer. For example, just by answering the\nfirst four questions, the system can narrow down Section 3.2 (which deals with 86 different occupancy classifications)\nto a handful of relevant classifications\u2014perhaps as few as five. This drastically reduces the amount of data that\nneeds to be processed and visualized, making the system faster and more user-friendly.\nThe process of extracting the necessary data from the BCBC to apply these six filtering questions will be handled\nusing the GPT-4 API. By passing GPT-4 a specific building code, it will be prompted to automatically identify\nand extract relevant information for each of the six criteria above. This newly required infor"
    },
    {
      "question": "How does the project utilize the large language model OpenAI GPT-4 to extract the structural hierarchy (digitization) and logical relationships of the BCBC?",
      "ground_truth": "The project leveraged the large language model OpenAI GPT-4 to extract the structural hierarchy (digitization) and logical relationships of the BCBC. The extracted data was then used to develop an interactive front-end demo for navigating and filtering the extracted codes.",
      "project": "bcbc_evaluation",
      "context": "reamlined and user-friendly approach to compliance and\ndesign.\nProject Overview\nThis project has four main goals:\n\u2022 Digitizing the British Columbia Building Code (BCBC),\n\u2022 Extracting the logical relationships between different codes,\n\u2022 Integration with a graph database management system to store the hierarchal structure and logical relationships\nof the BCBC\n\u2022 Developing an interactive front-end demo for navigating and filtering the extracted codes.\nThe project leveraged the large language model OpenAI GPT-4 to extract the structural hierarchy (digitization)\nand logical relationships of the BCBC. The graph database management system Neo4j was employed to streamline\ninteractions with the BCBC, making it more accessible and easier to understand for users. Below is a detailed\nbreakdown of the key phases of the project.\n1. Proof of Concept with ChatGPT\nThe first step in this project was to determine whether data and logic from the BCBC could be reliably extracted.\nTwo specialized ChatGPT mo"
    },
    {
      "question": "How does lowering the temperature parameter during logic extraction affect the output consistency and well-definedness of the extracted building code?",
      "ground_truth": "Lowering the temperature parameter in GPT models, which controls randomness, can help focus on producing consistent, well-defined logical structures rather than introducing variability. This is particularly useful for tasks like extracting building code logic, where accuracy and reliability are critical.",
      "project": "bcbc_evaluation",
      "context": "e particular nuances of the BCBC\u2019s\nlogical structure.\n3. Tuning the Temperature Parameter:The third improvement involves adjusting the temperature parameter\nduring the logic extraction process. The temperature setting in GPT models controls the randomness of\nthe output: a higher temperature (e.g., 0.8-1.0) generates more creative and varied responses, while a lower\ntemperature (e.g., 0.2-0.4) leads to more deterministic and focused output. For logic extraction, lowering the\ntemperature could help the model focus on producing consistent, well-defined logical structures rather than\nintroducing variability. Fine-tuning this parameter for the specific task of extracting building code logic will\nlikely result in more accurate and reliable results.\n4. Algorithm Accuracy Measurement Given the size of the BCBC, which spans over 1800 pages, calculating\nthe overall accuracy of the extraction algorithm remains a complex and unresolved issue. Without a clear benchmark\nfor measuring the accuracy of"
    },
    {
      "question": "How does the BCBC Building Code structure relate to the front-end demo development?",
      "ground_truth": "The BCBC Building Code structure is used to visualize and filter building codes, allowing users to interact with the digitized BCBC.",
      "project": "bcbc_evaluation",
      "context": "ierarchy: The structural hierarchy is represented by directed edges named CONTAINS. For example, a\nSentence node will connect to each of its Clause nodes using these CONTAINED directed edges.\n\u2022 Logical Relationships: These are also represented by directed edges. For example, if a Sentence requires all\nof its Clauses to be satisfied (the AND logical connective), AND edges connect each Clause node that must\nbe traversed back to the parent Sentence (via a RESULT directed edge) for that Sentence to be considered\nsatisfied.\nHere is an example:\nFigure 1: graph-example\n4. Front-End Demo Development\nThe final phase of the project focused on building a front-end user interface that would allow users to interact with\nthe digitized BCBC. This demo was built to:\n\u2022 Visualize the BCBC data and its logic as a graph, showcasing the structure of the building code and how\nvarious codes are interrelated.\n\u2022 Provide filtering capabilities so users could explore and narrow down the building codes based on t"
    },
    {
      "question": "What specific feature does the algorithm use to measure the accuracy of logic extraction and code structuring?",
      "ground_truth": "Fine-tuning the algorithm on logic conversion tasks should provide better accuracy metrics.",
      "project": "bcbc_evaluation",
      "context": "ithm remains a complex and unresolved issue. Without a clear benchmark\nfor measuring the accuracy of logic extraction and code structuring across such a large document, assessing the\nquality of the results is difficult.\nSolution: Fine-tuning the algorithm on logic conversion tasks should provide better accuracy metrics. This would\nallow the team to establish a clearer understanding of how well the extraction algorithm is performing. Additionally,\ncreating a sample set of manually validated logic conversions could serve as a baseline for evaluating the model\u2019s\noverall accuracy. By refining this process, future work will be able to quantitatively assess improvements and\npinpoint specific areas that need further optimization.\nFuture Work\n1. Efficient Filtering of Building CodesOne of the significant challenges in dealing with the British Columbia\nBuilding Code (BCBC) is its sheer size and complexity. With over 1800 pages and multiple sections, visualizing\nthe entire code at once or queryi"
    },
    {
      "question": "How does Neo4j enhance the BCBC's logical structure representation?",
      "ground_truth": "Neo4j enhances the BCBC's logical structure representation by allowing complex relationships to be stored and queried in an intuitive manner, enabling a clear and efficient way to represent the intricate legal text and complex logical structure of the building codes.",
      "project": "bcbc_evaluation",
      "context": " the GPT-4 API into automated pipelines, the team could parse large volumes of\ncontent with minimal manual intervention.\nOverall, this transition significantly boosted both the speed and accuracy of capturing the BCBC\u2019s intricate legal\ntext and complex logical structure.\n3. Integration with Neo4j\nOnce large sections of the BCBC were digitized and its logic extracted, the data was ingested into a Neo4j graph\ndatabase. Neo4j was chosen for its ability to represent complex relationships in a graph structure, allowing the\nBCBC\u2019s logical connections to be stored and queried in an intuitive manner. This phase involved writing an ingestion\nscript that utilizes Neo4j\u2019s declarative quary language, Cyphers, to embed the BCBC as a graph:\n\u2022 Nodes: Each building code element is embedded as a node, which has properties to hold the type (article,\nsentence, table, etc.) and descriptions (code text).\n\u2022 Hierarchy: The structural hierarchy is represented by directed edges named CONTAINS. For example, a\nS"
    },
    {
      "question": "What is the primary purpose of the Digitization and Logic Extraction of the British Columbia Building Code (BCBC) project?",
      "ground_truth": "The aim of this project is to digitize the British Columbia Building Code (BCBC) to improve its accessibility, usability, and efficiency for architects, engineers, and other professionals. ",
      "project": "bcbc_evaluation",
      "context": "Digitization and Logic Extraction of the British Columbia Building Code\n(BCBC)\nTimothy Fang, Ryan Bradshaw, Jonathan Doyle\nFebruary 4, 2025\nSummary\nThe aim of this project is to digitize the British Columbia Building Code (BCBC) to improve its accessibility,\nusability, and efficiency for architects, engineers, and other professionals. By leveraging large language models and\ngraph database technology, the project explored the feasibility of transforming the complex, lengthy BCBC document\ninto a machine-readable format, capturing both its structural hierarchy and logical relationships. Integrating a graph\ndatabase (Neo4j) enabled the visualization and traversal of these relationships, while a front-end demo showcased\nthe potential for interactive navigation and filtering. This first phase lays the groundwork for modernizing how\nprofessionals interact with building codes, offering a more streamlined and user-friendly approach to compliance and\ndesign.\nProject Overview\nThis project has fou"
    },
    {
      "question": "How can Sherpa be integrated into future iterations of the project for better table extraction and multi-page data handling?",
      "ground_truth": "Sherpa, specifically trained for these types of tasks, can be integrated into future iterations of the project to improve table extraction and multi-page data handling.",
      "project": "bcbc_evaluation",
      "context": "s or tables break across pages, making it\ndifficult to capture these in a unified format. This was particularly an issue when attempting to extract tables, and\nlower level codes (sentences, clauses, subclauses) that spilled onto multiple pages. Such cases led to incomplete or\nmalformed data.\nSolution: Instead of solely relying on the GPT-4 API for data extraction, future iterations of this project should\nconsider integrating an LLM model from Sherpa, which is specifically trained for these types of tasks. Initial tests\nwith Sherpa have shown promising results in dealing with multi-page data and table extractions more accurately.\nGiven that Sherpa operates under an MIT license, this makes it an appealing option for future work, as it offers\nrobust capabilities while remaining cost-effective.\n2. Imperfect Logic Extraction While the logic extraction generally performed well, there were instances where\nthe model failed to correctly identify the logical connectives (OR, AND, NOT) between co"
    },
    {
      "question": "How does the GPT-4 API improve the processing speed compared to smaller sections?",
      "ground_truth": "By integrating the GPT-4 API into automated pipelines, the team could parse large volumes of content with minimal turnaround times.",
      "project": "bcbc_evaluation",
      "context": "termine whether data and logic from the BCBC could be reliably extracted.\nTwo specialized ChatGPT models were developed:\n\u2022 Data Extraction: Converting the BCBC\u2019s complex text into JSON while preserving the structural hierarchy\nof articles, sentences, and clauses.\n\u2022 Logic Extraction: Mapping logical relationships between these elements to capture dependencies and\ncross-references.\nBy applying ChatGPT to smaller sections of the BCBC and confirming accurate extractions, the project moved\nforward with larger-scale automation.\n2. Scaling with the GPT-4 API\nFollowing the successful proof of concept, the team transitioned to using the GPT-4 API to handle larger sections of\nthe BCBC. This move brought two key advantages:\n\u2022 Faster Processing: The advanced model architecture handled longer and more complex text with greater\nefficiency, accelerating turnaround times.\n1\n\u2022 Scalability: By integrating the GPT-4 API into automated pipelines, the team could parse large volumes of\ncontent with minimal "
    },
    {
      "question": "Which specific criteria can be used to filter codes according to their usage?",
      "ground_truth": "Usage (assembly, industrial, residential, or commercial use)",
      "project": "bcbc_evaluation",
      "context": "omplexity. With over 1800 pages and multiple sections, visualizing\nthe entire code at once or querying large parts of the database can be inefficient and computationally expensive.\nWithout an effective filtering mechanism, users might face delays and difficulty navigating through relevant building\ncodes.\nTo address this, a filtering mechanism based on key criteria can be implemented. By answering a set of targeted\nquestions, users can significantly narrow down the relevant sections of the BCBC, particularly the occupancy\n3\nclassifications. This method not only reduces the complexity of visualizations but also optimizes the querying process\nbefore traversing code requirements using the extracted logic. The six criteria that can be used to filter codes include:\n1. Usage (assembly, industrial, residential, or commercial use)\n2. Building Square Footage\n3. Number of Storeys\n4. Construction Type (combustible or non-combustible)\n5. Sprinklered (yes or no)\n6. Street Exposure (number of streets"
    },
    {
      "question": "How can graph traversal be used to navigate between interconnected sections of the BC Building Code?",
      "ground_truth": "Graph traversal, such as depth-first search (DFS) or breadth-first search (BFS), can be employed to navigate through interconnected sections of the BC Building Code. This allows users to explore and understand how different building codes are related and dependent on each other.",
      "project": "bcbc_evaluation",
      "context": " Provide filtering capabilities so users could explore and narrow down the building codes based on the extracted\nlogic.\n\u2022 Demonstrate the power of graph traversal, enabling users to navigate between interconnected sections of the\nbuilding code seamlessly.\nChallenges and Future Work\nAlthough this beginning phase of the project had great progess, several challenges and areas for improvement were\nidentified during the process. Addressing these issues will ensure greater accuracy and efficiency in the future. Below\nare key difficulties encountered with proposed solutions, and discussion on future work.\n2\nChallenges\n1. Data Chunk Extraction from the BCBCOne of the major challenges was accurately extracting correct\nchucks of data (blocks of codes) from the BCBC, particularly when codes spanned multiple pages. PDF extraction\ncan be problematic due to inconsistencies in formatting, where sections or tables break across pages, making it\ndifficult to capture these in a unified format. This was p"
    },
    {
      "question": "What is the purpose of the front-end development component in the building code?",
      "ground_truth": "The purpose of the front-end development component in the building code is to demonstrate how Neo4j can be used as an interactive tool using Vis.js for graph visualization.",
      "project": "bcbc_evaluation",
      "context": "ntify\nand extract relevant information for each of the six criteria above. This newly required information will be then be\nadded as a property to the Neo4j node representing the building code in question. Thus allowing efficient filtering of\nbuilding codes.\n2. Front-End Development A basic React demo was built at the end of summer of 2024. The demo demonstrated\nhow Neo4j can be used as an interactive tool using Vis.js for graph visualization.\nDevelopment is ongoing; but here is a mockup of the envisioned tool.\n4\nFigure 2: front-end\n5\n"
    }
  ]
}
